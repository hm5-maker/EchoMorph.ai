{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPJdysG7AYtSWb8IuQa5w0y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hm5-maker/EchoMorph.ai/blob/main/Untitled3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Install dependencies (Torch, Demucs, faster-whisper, etc.)\n",
        "!pip -q install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
        "!pip -q install demucs faster-whisper ffmpeg-python soundfile pydub\n",
        "!sudo apt-get -y install ffmpeg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "99ksvsinUYmm",
        "outputId": "156eec77-92f6-46d0-e6bb-0521403c012a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.3/1.2 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.1/87.1 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.6/59.6 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m51.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.9/39.9 MB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.8/38.8 MB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m249.1/249.1 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.5/16.5 MB\u001b[0m \u001b[31m117.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.0/40.0 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.5/75.5 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for demucs (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for julius (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for dora-search (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for treetable (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 35 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python demux.py Video.mkv --outdir output --subs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HC-52lQoUzfj",
        "outputId": "afefa11c-5385-4d55-e529-70ca90ddc1e3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting video -> Video_video_only.mkv\n",
            "ffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n",
            "  built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
            "  libavutil      56. 70.100 / 56. 70.100\n",
            "  libavcodec     58.134.100 / 58.134.100\n",
            "  libavformat    58. 76.100 / 58. 76.100\n",
            "  libavdevice    58. 13.100 / 58. 13.100\n",
            "  libavfilter     7.110.100 /  7.110.100\n",
            "  libswscale      5.  9.100 /  5.  9.100\n",
            "  libswresample   3.  9.100 /  3.  9.100\n",
            "  libpostproc    55.  9.100 / 55.  9.100\n",
            "Input #0, matroska,webm, from 'Video.mkv':\n",
            "  Metadata:\n",
            "    COMPATIBLE_BRANDS: isommp42\n",
            "    MAJOR_BRAND     : mp42\n",
            "    MINOR_VERSION   : 0\n",
            "    ENCODER         : Lavf61.1.100\n",
            "  Duration: 00:01:24.48, start: 0.000000, bitrate: 397 kb/s\n",
            "  Stream #0:0: Video: h264 (High), yuv420p(tv, smpte170m/bt470bg/bt709, progressive), 640x360 [SAR 1:1 DAR 16:9], 30 fps, 30 tbr, 1k tbn, 60 tbc (default)\n",
            "    Metadata:\n",
            "      HANDLER_NAME    : ISO Media file produced by Google Inc. Created on: 07/03/2024.\n",
            "      VENDOR_ID       : [0][0][0][0]\n",
            "      ENCODER         : Lavc61.3.100 libx264\n",
            "      DURATION        : 00:01:24.469000000\n",
            "  Stream #0:1: Audio: vorbis, 44100 Hz, stereo, fltp (default)\n",
            "    Metadata:\n",
            "      HANDLER_NAME    : ISO Media file produced by Google Inc. Created on: 07/03/2024.\n",
            "      VENDOR_ID       : [0][0][0][0]\n",
            "      ENCODER         : Lavc61.3.100 libvorbis\n",
            "      DURATION        : 00:01:24.477000000\n",
            "Output #0, matroska, to 'output/Video_video_only.mkv':\n",
            "  Metadata:\n",
            "    COMPATIBLE_BRANDS: isommp42\n",
            "    MAJOR_BRAND     : mp42\n",
            "    MINOR_VERSION   : 0\n",
            "    encoder         : Lavf58.76.100\n",
            "  Stream #0:0: Video: h264 (High) (H264 / 0x34363248), yuv420p(tv, smpte170m/bt470bg/bt709, progressive), 640x360 [SAR 1:1 DAR 16:9], q=2-31, 30 fps, 30 tbr, 1k tbn, 1k tbc (default)\n",
            "    Metadata:\n",
            "      HANDLER_NAME    : ISO Media file produced by Google Inc. Created on: 07/03/2024.\n",
            "      VENDOR_ID       : [0][0][0][0]\n",
            "      ENCODER         : Lavc61.3.100 libx264\n",
            "      DURATION        : 00:01:24.469000000\n",
            "Stream mapping:\n",
            "  Stream #0:0 -> #0:0 (copy)\n",
            "Press [q] to stop, [?] for help\n",
            "frame= 2534 fps=0.0 q=-1.0 Lsize=    3074kB time=00:01:24.37 bitrate= 298.4kbits/s speed=3.51e+03x    \n",
            "video:3056kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.585092%\n",
            "Extracting audio #1 (vorbis, und) -> Video_a1_und.ogg\n",
            "ffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n",
            "  built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
            "  libavutil      56. 70.100 / 56. 70.100\n",
            "  libavcodec     58.134.100 / 58.134.100\n",
            "  libavformat    58. 76.100 / 58. 76.100\n",
            "  libavdevice    58. 13.100 / 58. 13.100\n",
            "  libavfilter     7.110.100 /  7.110.100\n",
            "  libswscale      5.  9.100 /  5.  9.100\n",
            "  libswresample   3.  9.100 /  3.  9.100\n",
            "  libpostproc    55.  9.100 / 55.  9.100\n",
            "Input #0, matroska,webm, from 'Video.mkv':\n",
            "  Metadata:\n",
            "    COMPATIBLE_BRANDS: isommp42\n",
            "    MAJOR_BRAND     : mp42\n",
            "    MINOR_VERSION   : 0\n",
            "    ENCODER         : Lavf61.1.100\n",
            "  Duration: 00:01:24.48, start: 0.000000, bitrate: 397 kb/s\n",
            "  Stream #0:0: Video: h264 (High), yuv420p(tv, smpte170m/bt470bg/bt709, progressive), 640x360 [SAR 1:1 DAR 16:9], 30 fps, 30 tbr, 1k tbn, 60 tbc (default)\n",
            "    Metadata:\n",
            "      HANDLER_NAME    : ISO Media file produced by Google Inc. Created on: 07/03/2024.\n",
            "      VENDOR_ID       : [0][0][0][0]\n",
            "      ENCODER         : Lavc61.3.100 libx264\n",
            "      DURATION        : 00:01:24.469000000\n",
            "  Stream #0:1: Audio: vorbis, 44100 Hz, stereo, fltp (default)\n",
            "    Metadata:\n",
            "      HANDLER_NAME    : ISO Media file produced by Google Inc. Created on: 07/03/2024.\n",
            "      VENDOR_ID       : [0][0][0][0]\n",
            "      ENCODER         : Lavc61.3.100 libvorbis\n",
            "      DURATION        : 00:01:24.477000000\n",
            "Output #0, ogg, to 'output/Video_a1_und.ogg':\n",
            "  Metadata:\n",
            "    COMPATIBLE_BRANDS: isommp42\n",
            "    MAJOR_BRAND     : mp42\n",
            "    MINOR_VERSION   : 0\n",
            "    encoder         : Lavf58.76.100\n",
            "  Stream #0:0: Audio: vorbis, 44100 Hz, stereo, fltp (default)\n",
            "    Metadata:\n",
            "      HANDLER_NAME    : ISO Media file produced by Google Inc. Created on: 07/03/2024.\n",
            "      VENDOR_ID       : [0][0][0][0]\n",
            "      ENCODER         : Lavc61.3.100 libvorbis\n",
            "      DURATION        : 00:01:24.477000000\n",
            "      COMPATIBLE_BRANDS: isommp42\n",
            "      MAJOR_BRAND     : mp42\n",
            "      MINOR_VERSION   : 0\n",
            "Stream mapping:\n",
            "  Stream #0:1 -> #0:0 (copy)\n",
            "Press [q] to stop, [?] for help\n",
            "size=    1005kB time=00:01:24.47 bitrate=  97.5kbits/s speed=1.66e+03x    \n",
            "video:0kB audio:991kB subtitle:0kB other streams:0kB global headers:4kB muxing overhead: 1.363910%\n",
            "No subtitle streams found or --subs not set.\n",
            "Done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ffmpeg -i /content/output/Video_a1_und.ogg /content/output/Video_a1_und.wav"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4MzrMMHUWtFz",
        "outputId": "a27508ef-c42f-40b3-d595-4ed3b0865329"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n",
            "  built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
            "  libavutil      56. 70.100 / 56. 70.100\n",
            "  libavcodec     58.134.100 / 58.134.100\n",
            "  libavformat    58. 76.100 / 58. 76.100\n",
            "  libavdevice    58. 13.100 / 58. 13.100\n",
            "  libavfilter     7.110.100 /  7.110.100\n",
            "  libswscale      5.  9.100 /  5.  9.100\n",
            "  libswresample   3.  9.100 /  3.  9.100\n",
            "  libpostproc    55.  9.100 / 55.  9.100\n",
            "Input #0, ogg, from '/content/output/Video_a1_und.ogg':\n",
            "  Duration: 00:01:24.48, start: 0.000272, bitrate: 97 kb/s\n",
            "  Stream #0:0: Audio: vorbis, 44100 Hz, stereo, fltp, 112 kb/s\n",
            "    Metadata:\n",
            "      HANDLER_NAME    : ISO Media file produced by Google Inc. Created on: 07/03/2024.\n",
            "      VENDOR_ID       : [0][0][0][0]\n",
            "      ENCODER         : Lavc61.3.100 libvorbis\n",
            "      DURATION        : 00:01:24.477000000\n",
            "      COMPATIBLE_BRANDS: isommp42\n",
            "      MAJOR_BRAND     : mp42\n",
            "      MINOR_VERSION   : 0\n",
            "Stream mapping:\n",
            "  Stream #0:0 -> #0:0 (vorbis (native) -> pcm_s16le (native))\n",
            "Press [q] to stop, [?] for help\n",
            "Output #0, wav, to '/content/output/Video_a1_und.wav':\n",
            "  Metadata:\n",
            "    ISFT            : Lavf58.76.100\n",
            "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 44100 Hz, stereo, s16, 1411 kb/s\n",
            "    Metadata:\n",
            "      HANDLER_NAME    : ISO Media file produced by Google Inc. Created on: 07/03/2024.\n",
            "      VENDOR_ID       : [0][0][0][0]\n",
            "      MINOR_VERSION   : 0\n",
            "      DURATION        : 00:01:24.477000000\n",
            "      COMPATIBLE_BRANDS: isommp42\n",
            "      MAJOR_BRAND     : mp42\n",
            "      encoder         : Lavc58.134.100 pcm_s16le\n",
            "size=       2kB time=00:00:00.00 bitrate=6566.5kbits/s speed= 138x    \rsize=   14552kB time=00:01:24.47 bitrate=1411.2kbits/s speed= 294x    \n",
            "video:0kB audio:14552kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.000523%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Colab\n",
        "!apt -y install ffmpeg\n",
        "!pip -q install -U torch torchaudio soundfile librosa tqdm openai-whisper\n",
        "!pip -q install resemblyzer spectralcluster librosa soundfile scikit-learn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NMauFVdbAJBg",
        "outputId": "f9b21e35-e9ad-444a-8307-9bfce19150ea"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 35 not upgraded.\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m803.2/803.2 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.2/66.2 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.7/15.7 MB\u001b[0m \u001b[31m93.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for webrtcvad (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for typing (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Install deps (Colab) ---\n",
        "import os, csv, math, subprocess\n",
        "import numpy as np\n",
        "import soundfile as sf\n",
        "import librosa\n",
        "\n",
        "from resemblyzer import VoiceEncoder, preprocess_wav\n",
        "from spectralcluster import SpectralClusterer\n",
        "from sklearn.metrics import silhouette_score\n",
        "from sklearn.metrics.pairwise import cosine_distances\n",
        "\n",
        "# ========= USER CONFIG =========\n",
        "AUDIO_IN = \"/content/output/Video_a1_und.wav\"          # your input audio (wav/mp3/m4a etc)\n",
        "TMP_WAV  = \"/content/_tmp_16k_mono.wav\"  # internal standardized path\n",
        "CSV_OUT  = \"/content/transcript_with_speakers.csv\"\n",
        "WHISPER_MODEL = \"large-v3\"               # or \"small\"/\"medium\" if RAM-limited\n",
        "LANG = \"ja\"                               # force Japanese (or None to autodetect)\n",
        "MIN_SEG_DUR = 0.35                        # seconds; too-short segments can be merged for better embeddings\n",
        "K_MIN, K_MAX = 2, 6                       # search this range for #speakers (set both equal to force k)\n",
        "# =================================\n",
        "\n",
        "# --- 0) Standardize audio: mono, 16k ---\n",
        "subprocess.run([\n",
        "    \"ffmpeg\", \"-y\", \"-i\", AUDIO_IN,\n",
        "    \"-ac\", \"1\", \"-ar\", \"16000\",\n",
        "    \"-vn\", TMP_WAV\n",
        "], check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "\n",
        "# --- 1) Transcribe with Whisper ---\n",
        "import torch, whisper\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model = whisper.load_model(WHISPER_MODEL, device=device)\n",
        "\n",
        "transcribe_kwargs = dict(\n",
        "    fp16=(device==\"cuda\"),\n",
        "    word_timestamps=False,\n",
        "    condition_on_previous_text=False\n",
        ")\n",
        "if LANG:\n",
        "    transcribe_kwargs.update(language=LANG, task=\"transcribe\")\n",
        "\n",
        "result = model.transcribe(TMP_WAV, **transcribe_kwargs)\n",
        "segments = result.get(\"segments\", [])\n",
        "if not segments:\n",
        "    raise RuntimeError(\"No segments from Whisper. Check audio or model settings.\")\n",
        "\n",
        "# --- 2) Load standardized audio array for slicing ---\n",
        "wav, sr = sf.read(TMP_WAV)   # sr should be 16000\n",
        "if wav.ndim > 1:\n",
        "    wav = wav.mean(axis=1)\n",
        "\n",
        "# Helper to grab samples for a time window\n",
        "def slice_audio(wav, sr, t0, t1):\n",
        "    i0 = max(0, int(round(t0 * sr)))\n",
        "    i1 = min(len(wav), int(round(t1 * sr)))\n",
        "    return wav[i0:i1]\n",
        "\n",
        "# (Optional) Merge too-short adjacent segments to get stabler embeddings\n",
        "merged = []\n",
        "for seg in segments:\n",
        "    if not merged:\n",
        "        merged.append(seg.copy())\n",
        "    else:\n",
        "        last = merged[-1]\n",
        "        dur = seg[\"end\"] - seg[\"start\"]\n",
        "        # If current seg is tiny, merge into previous (only for embedding; we still keep original times/text)\n",
        "        if dur < MIN_SEG_DUR:\n",
        "            last[\"end\"] = seg[\"end\"]\n",
        "            last[\"text\"] = (last.get(\"text\",\"\") + \" \" + seg.get(\"text\",\"\")).strip()\n",
        "        else:\n",
        "            merged.append(seg.copy())\n",
        "\n",
        "# --- 3) Compute one embedding per (possibly merged) segment and map back ---\n",
        "encoder = VoiceEncoder()  # CPU is fine; GPU will be faster\n",
        "embs = []\n",
        "emb_map_idx = []  # for each merged index, which original segment indices it covers\n",
        "\n",
        "# Build a mapping: for each merged segment, list original segment indices it spans\n",
        "def overlaps(a_start, a_end, b_start, b_end, eps=1e-6):\n",
        "    return not (a_end <= b_start + eps or b_end <= a_start + eps)\n",
        "\n",
        "for mi, mseg in enumerate(merged):\n",
        "    m_audio = slice_audio(wav, sr, mseg[\"start\"], mseg[\"end\"])\n",
        "    # preprocess_wav normalizes loudness etc.\n",
        "    # If the chunk is extremely short/silent, fall back to zeros to avoid errors.\n",
        "    if len(m_audio) < int(0.2 * sr):\n",
        "        # Make a tiny pad to avoid failure\n",
        "        m_audio = np.pad(m_audio, (0, int(0.2 * sr) - len(m_audio)), mode='edge')\n",
        "    m_wav = preprocess_wav(m_audio, source_sr=sr)\n",
        "    emb = encoder.embed_utterance(m_wav)\n",
        "    embs.append(emb)\n",
        "\n",
        "embs = np.vstack(embs)  # shape [M, D]\n",
        "\n",
        "# --- 4) Decide number of speakers (K) by silhouette over K_MIN..K_MAX ---\n",
        "def run_spectral(embeddings, k):\n",
        "    # SpectralClusterer expects L2 space; cosine still works well with default params\n",
        "    # Force a fixed k by setting min/max clusters\n",
        "    clust = SpectralClusterer(\n",
        "        min_clusters=k,\n",
        "        max_clusters=k,\n",
        "        p_percentile=0.90,\n",
        "        gaussian_blur_sigma=1\n",
        "    )\n",
        "    labels = clust.predict(embeddings)\n",
        "    return np.array(labels)\n",
        "\n",
        "if K_MIN == K_MAX:\n",
        "    best_k = K_MIN\n",
        "    best_labels = run_spectral(embs, best_k)\n",
        "else:\n",
        "    best_k, best_labels, best_score = None, None, -1.0\n",
        "    # Use cosine distances for silhouette\n",
        "    cos_d = cosine_distances(embs)\n",
        "    for k in range(K_MIN, min(K_MAX, len(embs)) + 1):\n",
        "        try:\n",
        "            labels = run_spectral(embs, k)\n",
        "            # If all in one cluster, silhouette is invalid\n",
        "            if len(np.unique(labels)) < 2:\n",
        "                continue\n",
        "            score = silhouette_score(cos_d, labels, metric=\"precomputed\")\n",
        "            if score > best_score:\n",
        "                best_k, best_labels, best_score = k, labels, score\n",
        "        except Exception:\n",
        "            continue\n",
        "    if best_labels is None:\n",
        "        # Fallback: everything is Speaker 1\n",
        "        best_k, best_labels = 1, np.zeros(len(embs), dtype=int)\n",
        "\n",
        "# --- 5) Propagate merged labels back to original Whisper segments ---\n",
        "# Build interval → label map from merged to all original segments by overlap\n",
        "def assign_labels_to_original(segments, merged, merged_labels):\n",
        "    labels_per_seg = [None] * len(segments)\n",
        "    m_idx = 0\n",
        "    for si, seg in enumerate(segments):\n",
        "        s0, s1 = seg[\"start\"], seg[\"end\"]\n",
        "        # Move m_idx forward until merged[m_idx] overlaps seg\n",
        "        while m_idx < len(merged) and merged[m_idx][\"end\"] <= s0:\n",
        "            m_idx += 1\n",
        "        # Check current and maybe next merged entry for overlap\n",
        "        candidates = []\n",
        "        for mj in (m_idx, m_idx+1):\n",
        "            if 0 <= mj < len(merged):\n",
        "                ms0, ms1 = merged[mj][\"start\"], merged[mj][\"end\"]\n",
        "                if overlaps(s0, s1, ms0, ms1):\n",
        "                    # weight by overlap duration\n",
        "                    ov = max(0.0, min(s1, ms1) - max(s0, ms0))\n",
        "                    candidates.append((ov, merged_labels[mj]))\n",
        "        if candidates:\n",
        "            # pick label with max overlap\n",
        "            lbl = sorted(candidates, key=lambda x: -x[0])[0][1]\n",
        "        else:\n",
        "            lbl = 0  # default to first speaker if something odd\n",
        "        labels_per_seg[si] = int(lbl)\n",
        "    return labels_per_seg\n",
        "\n",
        "labels_per_seg = assign_labels_to_original(segments, merged, best_labels)\n",
        "\n",
        "# Map cluster id -> Speaker N (order by first appearance)\n",
        "unique_order = []\n",
        "for lbl in labels_per_seg:\n",
        "    if lbl not in unique_order:\n",
        "        unique_order.append(lbl)\n",
        "id_to_name = {lbl: f\"Speaker {i+1}\" for i, lbl in enumerate(unique_order)}\n",
        "\n",
        "# --- 6) Write CSV (Excel-friendly UTF-8 with BOM) ---\n",
        "with open(CSV_OUT, \"w\", newline=\"\", encoding=\"utf-8-sig\") as f:\n",
        "    w = csv.writer(f, quoting=csv.QUOTE_ALL)\n",
        "    w.writerow([\"start\", \"end\", \"duration\", \"speaker\", \"text\"])\n",
        "    for seg, lbl in zip(segments, labels_per_seg):\n",
        "        start = float(seg.get(\"start\", 0.0))\n",
        "        end   = float(seg.get(\"end\", start))\n",
        "        text  = seg.get(\"text\", \"\").replace(\"\\r\\n\", \" \").replace(\"\\n\", \" \").strip()\n",
        "        w.writerow([round(start,3), round(end,3), round(end-start,3), id_to_name[lbl], text])\n",
        "\n",
        "print(f\"Done. Speakers: {len(id_to_name)} → {CSV_OUT}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tEFCkShBEf8Q",
        "outputId": "da930ef7-5260-486f-fbfd-7c96544219ab"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████████████████████████████████| 2.88G/2.88G [00:49<00:00, 62.9MiB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded the voice encoder model on cpu in 0.15 seconds.\n",
            "Done. Speakers: 1 → /content/transcript_with_speakers.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(CSV_OUT)\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "hXoOWmU9LZof",
        "outputId": "1ee12135-f5e3-4289-a2a7-194027f404a5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   start    end  duration    speaker            text\n",
              "0   0.00   2.70      2.70  Speaker 1  俺は必ず隙を見てお前に勝つぞ\n",
              "1   2.70   4.52      1.82  Speaker 1        俺はお前じゃない\n",
              "2   4.52   6.62      2.10  Speaker 1         かまど炭治郎だ\n",
              "3   6.62   8.84      2.22  Speaker 1       かまぼここんぱちろ\n",
              "4   8.84  11.00      2.16  Speaker 1           お前に勝つ"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-aeaaa1c0-68af-4fdf-897e-bfe27dc4cecc\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>start</th>\n",
              "      <th>end</th>\n",
              "      <th>duration</th>\n",
              "      <th>speaker</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.00</td>\n",
              "      <td>2.70</td>\n",
              "      <td>2.70</td>\n",
              "      <td>Speaker 1</td>\n",
              "      <td>俺は必ず隙を見てお前に勝つぞ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.70</td>\n",
              "      <td>4.52</td>\n",
              "      <td>1.82</td>\n",
              "      <td>Speaker 1</td>\n",
              "      <td>俺はお前じゃない</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.52</td>\n",
              "      <td>6.62</td>\n",
              "      <td>2.10</td>\n",
              "      <td>Speaker 1</td>\n",
              "      <td>かまど炭治郎だ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6.62</td>\n",
              "      <td>8.84</td>\n",
              "      <td>2.22</td>\n",
              "      <td>Speaker 1</td>\n",
              "      <td>かまぼここんぱちろ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>8.84</td>\n",
              "      <td>11.00</td>\n",
              "      <td>2.16</td>\n",
              "      <td>Speaker 1</td>\n",
              "      <td>お前に勝つ</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-aeaaa1c0-68af-4fdf-897e-bfe27dc4cecc')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-aeaaa1c0-68af-4fdf-897e-bfe27dc4cecc button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-aeaaa1c0-68af-4fdf-897e-bfe27dc4cecc');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-c845cd87-94ad-4610-ad54-9297830bbeee\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c845cd87-94ad-4610-ad54-9297830bbeee')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-c845cd87-94ad-4610-ad54-9297830bbeee button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 39,\n  \"fields\": [\n    {\n      \"column\": \"start\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 27.661643954920663,\n        \"min\": 0.0,\n        \"max\": 84.46,\n        \"num_unique_values\": 39,\n        \"samples\": [\n          78.22,\n          81.36,\n          8.84\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"end\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 29.108906141147642,\n        \"min\": 2.7,\n        \"max\": 114.44,\n        \"num_unique_values\": 39,\n        \"samples\": [\n          79.64,\n          81.74,\n          11.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"duration\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.692551481465902,\n        \"min\": 0.38,\n        \"max\": 29.98,\n        \"num_unique_values\": 33,\n        \"samples\": [\n          0.54,\n          2.8,\n          2.06\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"speaker\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Speaker 1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 39,\n        \"samples\": [\n          \"\\u30a2\\u30de\\u30c9\\u30b8\\u30e3\\u30f3\\u30b8\\u30ed\\u30fc\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install deep_translator\n",
        "\n",
        "from deep_translator import GoogleTranslator\n",
        "\n",
        "# Function to translate text\n",
        "def translate_text(text):\n",
        "    try:\n",
        "        # Translate Japanese to English using deep_translator\n",
        "        translation = GoogleTranslator(source='ja', target='en').translate(text)\n",
        "        return translation\n",
        "    except Exception as e:\n",
        "        print(f\"Error translating text: {text} - {e}\")\n",
        "        return None\n",
        "\n",
        "# Apply translation to the 'text' column\n",
        "df['english_translation'] = df['text'].apply(translate_text)\n",
        "\n",
        "# Save the updated dataframe to the CSV file\n",
        "df.to_csv(CSV_OUT, index=False, encoding=\"utf-8-sig\")\n",
        "\n",
        "print(f\"Added English translation column and updated {CSV_OUT}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l3rqp9bOLm6h",
        "outputId": "b46fb9ee-2371-4941-abbf-f783d40c7107"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting deep_translator\n",
            "  Downloading deep_translator-1.11.4-py3-none-any.whl.metadata (30 kB)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.9.1 in /usr/local/lib/python3.12/dist-packages (from deep_translator) (4.13.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.23.0 in /usr/local/lib/python3.12/dist-packages (from deep_translator) (2.32.4)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4<5.0.0,>=4.9.1->deep_translator) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4<5.0.0,>=4.9.1->deep_translator) (4.15.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.23.0->deep_translator) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.23.0->deep_translator) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.23.0->deep_translator) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.23.0->deep_translator) (2025.8.3)\n",
            "Downloading deep_translator-1.11.4-py3-none-any.whl (42 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/42.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.3/42.3 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: deep_translator\n",
            "Successfully installed deep_translator-1.11.4\n",
            "Added English translation column and updated /content/transcript_with_speakers.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install api_keys sounddevice"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tHJ5r-rdQ8Ze",
        "outputId": "3b9695a3-9f54-45c0-fe68-067ee0be2496"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement api_keys (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for api_keys\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import base64, requests\n",
        "\n",
        "def audio_bytes_from_response(resp):\n",
        "    \"\"\"\n",
        "    Accepts Murf SDK response and returns raw audio bytes.\n",
        "    Handles:\n",
        "      - resp.audio_file as bytes\n",
        "      - resp.audio_file as base64 string\n",
        "      - resp.audio_url / resp.url as downloadable URL\n",
        "    \"\"\"\n",
        "    # 1) Preferred: bytes already\n",
        "    af = getattr(resp, \"audio_file\", None)\n",
        "    if isinstance(af, (bytes, bytearray)):\n",
        "        return bytes(af)\n",
        "\n",
        "    # 2) String: URL or base64\n",
        "    if isinstance(af, str) and af:\n",
        "        s = af.strip()\n",
        "        if s.startswith(\"http://\") or s.startswith(\"https://\"):\n",
        "            r = requests.get(s, timeout=60)\n",
        "            r.raise_for_status()\n",
        "            return r.content\n",
        "        # assume base64 if not a URL\n",
        "        try:\n",
        "            return base64.b64decode(s)\n",
        "        except Exception:\n",
        "            pass  # fall through to check other fields\n",
        "\n",
        "    # 3) Fallback: some SDKs expose URL on a different attr\n",
        "    url = getattr(resp, \"audio_url\", None) or getattr(resp, \"url\", None)\n",
        "    if isinstance(url, str) and url.startswith((\"http://\", \"https://\")):\n",
        "        r = requests.get(url, timeout=60)\n",
        "        r.raise_for_status()\n",
        "        return r.content\n",
        "\n",
        "    raise TypeError(\"Could not obtain audio bytes from Murf response\")\n"
      ],
      "metadata": {
        "id": "lmfq0lJuRd2q"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install murf pydub requests\n",
        "\n",
        "import os, csv, base64, requests\n",
        "from datetime import datetime\n",
        "from murf import Murf\n",
        "from pydub import AudioSegment\n",
        "from google.colab import userdata # Import userdata to access secrets\n",
        "\n",
        "# === CONFIG ===================================================================\n",
        "CSV_PATH = \"/content/transcript_with_speakers.csv\"                 # must have: speaker,english_translation\n",
        "OUT_ROOT = \"generated_tts\"\n",
        "ADD_TIMESTAMP = True\n",
        "GAP_MS = 700   # silence gap between lines\n",
        "\n",
        "# Real voices\n",
        "# Note: Replace these with actual valid voice IDs from the Murf API\n",
        "# You can find valid voice IDs in the Murf API documentation or by using the GET /v1/speech/voices endpoint.\n",
        "voice_map = {\n",
        "    \"speaker 1\": {\"voice_id\": \"en-US-ken\", \"style\": \"Conversational\"}, # Example valid voice (replace)\n",
        "    # Add other speakers and their voice configs as needed, e.g.,\n",
        "    # \"speaker 2\": {\"voice_id\": \"en-US-natalie\", \"style\": \"Promo\"},\n",
        "}\n",
        "default_voice = {\"voice_id\": \"en-US-ken\",     \"style\": \"Conversational\"}  # fallback (replace)\n",
        "\n",
        "# Access API key from Colab Secrets\n",
        "API_KEY = userdata.get('MURF_API_KEY')\n",
        "if API_KEY is None:\n",
        "    raise RuntimeError(\"⚠️ MURF_API_KEY not found in Colab Secrets. Please add it.\")\n",
        "\n",
        "client = Murf(api_key=API_KEY)\n",
        "\n",
        "# Output folder (timestamped)\n",
        "ts = datetime.now().strftime(\"%Y%m%d_%H%M%S\") if ADD_TIMESTAMP else \"run\"\n",
        "OUT_DIR = os.path.join(OUT_ROOT, f\"run_{ts}\")\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "OUT_MIX = os.path.join(OUT_DIR, \"conversation.wav\")\n",
        "\n",
        "# === Helper ===================================================================\n",
        "def audio_bytes_from_response(resp):\n",
        "    \"\"\"Normalize Murf SDK response into raw audio bytes.\"\"\"\n",
        "    af = getattr(resp, \"audio_file\", None)\n",
        "\n",
        "    # Already bytes\n",
        "    if isinstance(af, (bytes, bytearray)):\n",
        "        return bytes(af)\n",
        "\n",
        "    # String: could be URL or base64\n",
        "    if isinstance(af, str) and af:\n",
        "        s = af.strip()\n",
        "        if s.startswith(\"http://\") or s.startswith(\"https://\"):\n",
        "            r = requests.get(s, timeout=60)\n",
        "            r.raise_for_status()\n",
        "            return r.content\n",
        "        try:\n",
        "            return base64.b64decode(s)\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "    # Fallback: other attributes\n",
        "    url = getattr(resp, \"audio_url\", None) or getattr(resp, \"url\", None)\n",
        "    if isinstance(url, str) and url.startswith((\"http://\", \"https://\")):\n",
        "        r = requests.get(url, timeout=60)\n",
        "        r.raise_for_status()\n",
        "        return r.content\n",
        "\n",
        "    # Handle Murf SDK GenerateSpeechResponse object (assuming 'content' attribute)\n",
        "    if hasattr(resp, 'content') and isinstance(resp.content, bytes):\n",
        "         return resp.content\n",
        "\n",
        "\n",
        "    raise TypeError(\"Could not obtain audio bytes from Murf response\")\n",
        "\n",
        "# === Read CSV =================================================================\n",
        "rows = []\n",
        "with open(CSV_PATH, \"r\", encoding=\"utf-8-sig\") as f:\n",
        "    r = csv.DictReader(f)\n",
        "    if \"speaker\" not in r.fieldnames or \"english_translation\" not in r.fieldnames:\n",
        "        raise ValueError(\"CSV must have columns: speaker, english_translation\")\n",
        "    for row in r:\n",
        "        spk = (row.get(\"speaker\") or \"\").strip().lower()\n",
        "        txt = (row.get(\"english_translation\") or \"\").strip()\n",
        "        if txt:\n",
        "            rows.append({\"speaker\": spk, \"text\": txt})\n",
        "\n",
        "print(f\"Loaded {len(rows)} lines from {CSV_PATH}\")\n",
        "\n",
        "# === Generate TTS per line ====================================================\n",
        "generated_paths = []\n",
        "for i, d in enumerate(rows, start=1):\n",
        "    cfg = voice_map.get(d[\"speaker\"], default_voice)\n",
        "    out_path = os.path.join(OUT_DIR, f\"{i:04d}_{d['speaker'] or 'unknown'}.wav\")\n",
        "\n",
        "    if not os.path.exists(out_path):\n",
        "        # Ensure voice_id is passed correctly from the config\n",
        "        resp = client.text_to_speech.generate(\n",
        "            text=d[\"text\"],\n",
        "            voice_id=cfg.get(\"voice_id\"), # Get voice_id from config\n",
        "            style=cfg.get(\"style\")\n",
        "        )\n",
        "        audio_bytes = audio_bytes_from_response(resp)\n",
        "        with open(out_path, \"wb\") as f:\n",
        "            f.write(audio_bytes)\n",
        "\n",
        "    generated_paths.append(out_path)\n",
        "    print(f\"[OK] {i:04d} {d['speaker']} → {os.path.basename(out_path)}\")\n",
        "\n",
        "# === Stitch into one conversation ============================================\n",
        "combined = AudioSegment.silent(duration=0)\n",
        "gap = AudioSegment.silent(duration=GAP_MS)\n",
        "\n",
        "for idx, p in enumerate(generated_paths):\n",
        "    combined += AudioSegment.from_file(p)\n",
        "    if idx < len(generated_paths) - 1:\n",
        "        combined += gap\n",
        "\n",
        "combined.export(OUT_MIX, format=\"wav\")\n",
        "\n",
        "print(\"\\n✅ Done\")\n",
        "print(f\"Individual WAVs saved in: {OUT_DIR}\")\n",
        "print(f\"Final stitched mix: {OUT_MIX}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LLPdw3DlSZQ-",
        "outputId": "3461d5c0-b34c-4760-f862-f29bad0d3e98"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 39 lines from /content/transcript_with_speakers.csv\n",
            "[OK] 0001 speaker 1 → 0001_speaker 1.wav\n",
            "[OK] 0002 speaker 1 → 0002_speaker 1.wav\n",
            "[OK] 0003 speaker 1 → 0003_speaker 1.wav\n",
            "[OK] 0004 speaker 1 → 0004_speaker 1.wav\n",
            "[OK] 0005 speaker 1 → 0005_speaker 1.wav\n",
            "[OK] 0006 speaker 1 → 0006_speaker 1.wav\n",
            "[OK] 0007 speaker 1 → 0007_speaker 1.wav\n",
            "[OK] 0008 speaker 1 → 0008_speaker 1.wav\n",
            "[OK] 0009 speaker 1 → 0009_speaker 1.wav\n",
            "[OK] 0010 speaker 1 → 0010_speaker 1.wav\n",
            "[OK] 0011 speaker 1 → 0011_speaker 1.wav\n",
            "[OK] 0012 speaker 1 → 0012_speaker 1.wav\n",
            "[OK] 0013 speaker 1 → 0013_speaker 1.wav\n",
            "[OK] 0014 speaker 1 → 0014_speaker 1.wav\n",
            "[OK] 0015 speaker 1 → 0015_speaker 1.wav\n",
            "[OK] 0016 speaker 1 → 0016_speaker 1.wav\n",
            "[OK] 0017 speaker 1 → 0017_speaker 1.wav\n",
            "[OK] 0018 speaker 1 → 0018_speaker 1.wav\n",
            "[OK] 0019 speaker 1 → 0019_speaker 1.wav\n",
            "[OK] 0020 speaker 1 → 0020_speaker 1.wav\n",
            "[OK] 0021 speaker 1 → 0021_speaker 1.wav\n",
            "[OK] 0022 speaker 1 → 0022_speaker 1.wav\n",
            "[OK] 0023 speaker 1 → 0023_speaker 1.wav\n",
            "[OK] 0024 speaker 1 → 0024_speaker 1.wav\n",
            "[OK] 0025 speaker 1 → 0025_speaker 1.wav\n",
            "[OK] 0026 speaker 1 → 0026_speaker 1.wav\n",
            "[OK] 0027 speaker 1 → 0027_speaker 1.wav\n",
            "[OK] 0028 speaker 1 → 0028_speaker 1.wav\n",
            "[OK] 0029 speaker 1 → 0029_speaker 1.wav\n",
            "[OK] 0030 speaker 1 → 0030_speaker 1.wav\n",
            "[OK] 0031 speaker 1 → 0031_speaker 1.wav\n",
            "[OK] 0032 speaker 1 → 0032_speaker 1.wav\n",
            "[OK] 0033 speaker 1 → 0033_speaker 1.wav\n",
            "[OK] 0034 speaker 1 → 0034_speaker 1.wav\n",
            "[OK] 0035 speaker 1 → 0035_speaker 1.wav\n",
            "[OK] 0036 speaker 1 → 0036_speaker 1.wav\n",
            "[OK] 0037 speaker 1 → 0037_speaker 1.wav\n",
            "[OK] 0038 speaker 1 → 0038_speaker 1.wav\n",
            "[OK] 0039 speaker 1 → 0039_speaker 1.wav\n",
            "\n",
            "✅ Done\n",
            "Individual WAVs saved in: generated_tts/run_20250831_135533\n",
            "Final stitched mix: generated_tts/run_20250831_135533/conversation.wav\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "from pathlib import Path\n",
        "\n",
        "def merge_video_audio(video_path, audio_path, output_path=\"merged_output.mkv\"):\n",
        "    cmd = [\n",
        "        \"ffmpeg\", \"-y\",\n",
        "        \"-i\", str(video_path),\n",
        "        \"-i\", str(audio_path),\n",
        "        \"-c:v\", \"copy\",\n",
        "        \"-c:a\", \"aac\",   # or \"pcm_s16le\" if you want raw WAV audio inside MKV\n",
        "        \"-shortest\",\n",
        "        str(output_path)\n",
        "    ]\n",
        "    subprocess.run(cmd, check=True)\n",
        "    print(f\"Merged file saved as {output_path}\")\n",
        "\n",
        "# Example usage\n",
        "merge_video_audio(\"/content/output/Video_video_only.mkv\", \"/content/generated_tts/run_20250831_135533/conversation.wav\", \"final_with_audio.mkv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OD0UhPAOTmCY",
        "outputId": "48abc8ec-b4c2-42d1-fb36-57d7d6aa1376"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Merged file saved as final_with_audio.mkv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DMLbykjUazPT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}